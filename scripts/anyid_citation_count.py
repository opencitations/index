#!python
# Copyright (c) 2023 Ivan Heibi.
#
# Permission to use, copy, modify, and/or distribute this software for any purpose
# with or without fee is hereby granted, provided that the above copyright notice
# and this permission notice appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH
# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND
# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,
# OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,
# DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS
# SOFTWARE.
#
# v2.2
# New strategy to check unique citing entites
#
# v2.1
# Citations map could be created also using a CSV dump instead of Redis only
#
# v2
# A count of all unique citations is done to all the BRs (not only the ANYIDs that have multi OMIDs)

import csv
import argparse
from collections import defaultdict
from tqdm import tqdm
import re
import sys
import requests
from time import sleep
import json
import redis

# from zipfile import ZipFile
# import io

from oc.index.utils.logging import get_logger
from oc.index.utils.config import get_config

csv.field_size_limit(sys.maxsize)
config = get_config()
conf_br_ids = config.get("cnc", "br_ids").split(",")

'''
To create the omid map using the META BRs index (in CSV)
The META BRs index should be previously generated using 'meta2redis' command
'''
def read_omid_map(f_omidmap):
    global conf_br_ids

    omid_map = defaultdict(set)
    with open(f_omidmap, mode='r') as file:
        csv_reader = csv.reader(file)
        for row in csv_reader:
            if len(row) == 2:  # Ensure there are exactly two columns
                br_omid, anyids = row
                br_omid = br_omid
                for _id in anyids.split("; "):
                    for anyid_pref in conf_br_ids:
                        if _id.startswith(anyid_pref):
                            omid_map[br_omid].add( _id )

    return omid_map

'''
Create the omid citations index using the omid citations index CSV file
The omid citations index CSV file should be previously generated using 'cits2redis' command
RETURNS:
    * omid_citations_index: {<CITED_OMID>: [<CITING_OMID_1>, <CITING_OMID_2>, ... <CITING_OMID_N>]}
'''
def read_omid_citations_index(f_omid_citations_index):

    omid_citations_index = defaultdict(list)
    with open(f_omid_citations_index, mode='r') as file:
        csv_reader = csv.reader(file)

        #TEST
        # csv_reader = csv_reader[:45000]

        for row in csv_reader:
            if len(row) == 2:  # Ensure there are exactly two columns
                cited_omid, str_citing_omids = row
                omid_citations_index[cited_omid] = str_citing_omids.split("; ")

    return omid_citations_index

'''
PARAMS:
    + citing_omids: the list of citing OMIDs
    + omid_map: the map of OMID > ANYIDs
RETURNS:
    The unique number of citation count
'''
def count_unique_cits(citing_omids, omid_map):

    global conf_br_ids
    cits_count = 0

    # create a set for each different any_id
    idpref_index = {id_pref: set() for id_pref in conf_br_ids}

    # check if each anyid value of the citing entity is unique
    for a_citing_omid in citing_omids:
        is_unique_citing = True
        for __a_citing_anyid in omid_map[a_citing_omid]:
            for id_pref in conf_br_ids:
                if __a_citing_anyid.startswith(id_pref):
                    is_unique_citing = is_unique_citing and (not (__a_citing_anyid in idpref_index[id_pref]))
                    idpref_index[id_pref].add( __a_citing_anyid )

        if is_unique_citing:
            cits_count += 1

    # empty all
    for id_pref in idpref_index:
        idpref_index[id_pref] = None
    idpref_index = None

    return cits_count

    # --- Previous version
    # --------------------
    # # Get the ANYIDs of the citing OMIDS
    # # Count the unique ones
    # unique_brs_anyid = []
    # for a_citing_omid in citing_omids:
    #     _c_intersection = 0
    #     s_citing_anyids = omid_map[a_citing_omid].copy()
    #     for __unique in unique_brs_anyid:
    #         _c_intersection += len(__unique.intersection(s_citing_anyids))
    #     # if there is no common anyids with the other br entities
    #     if _c_intersection == 0:
    #         unique_brs_anyid.append(s_citing_anyids)
    #
    # return len(unique_brs_anyid)


def main():

    parser = argparse.ArgumentParser(description='Converts the citation count dump of OpenCitations Index based on BR OMIDs to any other ID (e.g., DOI, PMID)')
    parser.add_argument('--omidmap', required=True, help='Path to CSV dump containing the index/map of all BR in Meta (OMIDs) (*Note: generated by meta2redis)')
    # Data source in the format: <TYPE>:<VALUE>
    # E.G. REDIS:8 | CSV:/PATH/TO/OMID_CITAIONS_INDEX.csv
    parser.add_argument('--citations', default='redis:8', help='Either the Redis DB or CSV file storing all the citations of opencitations (*Note: populated by cits2redis). Specified in the form: <TYPE>:<VALUE>. E.G. REDIS:8 | CSV:/PATH/TO/OMID_CITAIONS_INDEX.csv')
    parser.add_argument('--id',  default='doi', help='Convert OMID(s) to a given ID')
    parser.add_argument('--out', default='./', help='Path to the output destination dir')
    args = parser.parse_args()
    logger = get_logger()

    # get ANYID Prefix. E:G. "doi"
    anyid_pref = args.id

    logger.info("Build a citation count for ANYID starting with the prefix: "+str(anyid_pref))

    # Build OMID map
    # FORMAT:
    #   <OMID>: SET(<anyid_pref>:<anyid_val>)
    # EXAMPLE:
    #   06804319241: {"doi:10.17615/3my7-0q76","pmid:18650518","pmid:18650512","doi:10.1056/nejme0804289","doi:10.1056/nejmoa0708975"}
    logger.info("Build OMID BR map ...")
    omid_map = read_omid_map(args.omidmap)
    logger.info("OMID MAP = "+str(len(omid_map.keys())))
    # Redis DB storing OC Index citations
    # FORMAT:
    #   <CITED-OMID>:[ <CITING-OMID-1>, <CITING-OMID-2>, ..., <CITING-OMID-N> ]
    # EXAMPLE:
    #   "06503922554": [\"062403812713\", \"0610298487\", \"06250181491\"]

    ds_cits_type, ds_cits_source = args.citations.lower().split(":")
    ds_cits_data = None
    logger.info("Build OMID Cits map via "+ds_cits_type+" ...")
    if ds_cits_type == "redis":
        ds_cits_data = redis.Redis(host='localhost', port=6379, db=ds_cits_source)
    elif ds_cits_type == "csv":
        ds_cits_data = read_omid_citations_index(ds_cits_source)

    # Results to dump at the end
    anyid_citation_count = dict()
    anyid_map = defaultdict(set)

    # PARAMS
    CHUNCK_SIZE = 10000

    # (1) Walk through all OMIDS in the OMID map (i.e. omid_map)
    logger.info("Walk through all OMIDS in the OMID map (i.e. omid_map) ...")
    l_br_omids = list(omid_map.keys())

    #TEST
    # l_br_omids = l_br_omids[:45000]

    #for cited_omid in tqdm(list(omid_map.keys())):
    for i in tqdm(range(0, len(l_br_omids), CHUNCK_SIZE)):

        # get the chunck list of omids
        cited_omid_chunk = l_br_omids[i:i + CHUNCK_SIZE]

        # a dict > OMID: REDIS-VAL
        if ds_cits_type == "redis":
            omid_cits = dict(zip(cited_omid_chunk, ds_cits_data.mget(cited_omid_chunk)))
        elif ds_cits_type == "csv":
            omid_cits = {k_cited_omid:ds_cits_data[k_cited_omid] for k_cited_omid in cited_omid_chunk}

        for cited_omid in omid_cits:

            # Get all citing OMIDs of a given OMID
            # citing_val = ds_cits_data.get( cited_omid )
            citing_val = omid_cits[cited_omid]

            if citing_val != None:

                citing_omids = None
                if ds_cits_type == "redis":
                    citing_omids = set( json.loads(citing_val.decode('utf-8')) )
                elif ds_cits_type == "csv":
                    citing_omids = set( citing_val )

                # Get the citation count of *cited_omid*
                citation_count = count_unique_cits(citing_omids, omid_map)

                # Save the citation count for each ANYID of the cited OMID if it starts with prefix needed (e.g., "doi")
                # and update the ANYID map, to monitor the number of OMIDs for each ANYID
                cited_anyids = omid_map[cited_omid].copy()
                for _anyid in cited_anyids:
                    if _anyid.startswith(anyid_pref):
                        anyid_map[_anyid].add(cited_omid)
                        anyid_citation_count[_anyid] = citation_count

    # (2) Work with ANYIDs that have multiple OMIDs
    # Filter the anyid_map previously created to include only ANYIDs that have multi OMIDs
    multi_any_ids = {_anyid:anyid_map[_anyid] for _anyid in anyid_map if len(anyid_map[_anyid]) > 1}

    # Walk throuh this new DICT multi_any_ids
    logger.info("Walk through all ANYIDs that have multiple OMIDs ...")
    l_br_anyids = list(multi_any_ids.keys())

    #for _anyid in tqdm(list(multi_any_ids.keys())):
    for i in tqdm(range(0, len(l_br_anyids), CHUNCK_SIZE)):

        # get the chunck list of omids
        cited_anyid_chunk = l_br_anyids[i:i + CHUNCK_SIZE]

        l_cited_omids = [_omid for _anyid in cited_anyid_chunk for _omid in multi_any_ids[_anyid]]

        # a dict > OMID: REDIS-VAL
        omid_cits_map = None
        if ds_cits_type == "redis":
            omid_cits_map = dict(zip(l_cited_omids, ds_cits_data.mget(l_cited_omids)))
        elif ds_cits_type == "csv":
            omid_cits_map = {_omid:ds_cits_data[_omid] for _omid in l_cited_omids}

        # Elaborate each ANYID in the chunck using the redis map above
        for _anyid in cited_anyid_chunk:

            # Create a set with all citing OMIDs of _anyid OMIDs
            citing_omids = set()
            for cited_omid in multi_any_ids[_anyid]:
                citing_val = omid_cits_map[cited_omid]

                if citing_val != None:
                    if ds_cits_type == "redis":
                        citing_omids.union( set( json.loads(citing_val.decode('utf-8')) ) )
                    elif ds_cits_type == "csv":
                        citing_omids.union( set(citing_val) )

            # Get the citation count of *_anyid*
            citation_count = count_unique_cits(citing_omids, omid_map)

            # update the numer of citations of the ANYIDs with multi OMIDs with the new citation count
            anyid_citation_count[_anyid] = citation_count


    # dump anyid - citation count
    logger.info('Saving the citation counts of '+anyid_pref+' BRs ...')
    with open(args.out+anyid_pref+"_citation_count.csv", mode='w', newline='') as output_csvfile:
        writer = csv.writer(output_csvfile)
        writer.writerow([anyid_pref, 'citation_count'])
        for c in [(k,anyid_citation_count[k]) for k in anyid_citation_count]:
            writer.writerow([c[0],str(c[1])])

    # dump duplicates
    logger.info('Saving duplicated BR entites ...')
    with open(args.out+anyid_pref+"_dupilcates.csv", mode='w', newline='') as output_csvfile:
        writer = csv.writer(output_csvfile)
        writer.writerow([anyid_pref, 'num_duplicates'])

        # Print length
        #for c in [ (any_id, len(multi_any_ids[any_id]) ) for any_id in multi_any_ids]:
        #    writer.writerow([c[0],str(c[1])])

        # Print content
        for c in [ (any_id, multi_any_ids[any_id] ) for any_id in multi_any_ids]:
            writer.writerow([c[0],str(c[1])])


#if __name__ == "__main__":
#    main()
